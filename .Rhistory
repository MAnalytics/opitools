nsim_exp_scores <- NULL
for(m in seq_len(nsim)){ #m<-1
#create backup of the all 'neutrals'
#for simulation, neutral remains untouched
#to be appended back later
neutral_osd <- osd_data %>%
dplyr::filter(sentiment == 'neutral')
#filter neutral
#simul is based on permutation
#of positv and negat sentimnt labels
p1 <- osd_data %>%
dplyr::filter(sentiment!="neutral")%>%
dplyr::group_by(keywords)%>%
dplyr::mutate(nnrow=n())%>%
mutate(prob1=nnrow/nrow(osd_data))%>% #prob of absent
ungroup()%>%
dplyr::group_by(keywords, sentiment) %>%
dplyr::mutate(pos_neg_count=n())%>%
mutate(prob2=pos_neg_count/nnrow)##%>%
len_excl_neutral <- nrow(p1)
ab_class_sent <- p1[which(p1$keywords == "absent"),2]
length_present_group <- length(which(p1$keywords == "present"))
#now collate the unique probabilities of 'absent' class
p1_prob <- p1 %>%
dplyr::filter(keywords == "absent")%>%
dplyr::distinct(sentiment, .keep_all = TRUE)%>%
dplyr::select(sentiment, prob2)
if(nsim == 1){
set.seed(len_excl_neutral)
new_ex_class_sent = sample(p1_prob$sentiment, length_present_group, replace=TRUE, prob = p1_prob$prob2)
#new_ex_class_sent = sample(c("negative", "positive"), sum(unique(p1$nnrow)), replace=TRUE, prob = c(unique(p1$prob_new_assign),(1-unique(p1$prob_new_assign))))
}
if(nsim > 1){
#generate samples of present class using the prob of absent class
if(m == 1){
set.seed(len_excl_neutral)
new_ex_class_sent = sample(p1_prob$sentiment, length_present_group, replace=TRUE, prob = p1_prob$prob2)
#new_ex_class_sent = sample(c("negative", "positive"), sum(unique(p1$nnrow)), replace=TRUE, prob = c(unique(p1$prob_new_assign),(1-unique(p1$prob_new_assign))))
}
if(m > 1){
#set.seed(nrow(data))
new_ex_class_sent = sample(p1_prob$sentiment, length_present_group, replace=TRUE, prob = p1_prob$prob2)
#new_ex_class_sent = sample(c("negative", "positive"), sum(unique(p1$nnrow)), replace=TRUE, prob = c(unique(p1$prob_new_assign),(1-unique(p1$prob_new_assign))))
}
}
#unique(p1$nnrow)[1]
new_ex_class_sent
new_sentiment_list <- c(new_ex_class_sent, as.vector(unlist(ab_class_sent))) #length(new_sentiment_list)#nrow(p1)
#new_sentiment_list <- new_ex_class_sent
#p1[which(p1$keywords == "present"), 3] <- new_ex_class_sent
final_p1 <- data.frame(cbind(p1, sentiment2=new_sentiment_list))
head(final_p1)
#expected
final_p1_ESD <- final_p1 %>%
dplyr::select(ID, sentiment, keywords, sentiment2)%>%
mutate(sentiment = sentiment2)%>%
dplyr::select(-c(sentiment2))
#now, prepare compute different opinion scores
#append neutral list
final_p1_ESD <- rbind(final_p1_ESD, neutral_osd)
afinn_ESD <- final_p1_ESD %>%
group_by(sentiment)%>%
#count the proportion of
dplyr::summarise(n=n())
#to ensure that each value exist
sent_gr <- data.frame(sentiment=c("negative", "positive", "neutral"),
n=0)
wh <- sent_gr$sentiment %in% afinn_ESD$sentiment
#
afinn_ESD <- afinn_ESD %>%
bind_rows(sent_gr[which(wh==FALSE),])
#calculate opinion score
if (metric %in% c(1:4)){
if(metric == 1){
total_n <- sum(afinn_ESD$n)
afinn_ESD <- afinn_ESD %>%
dplyr::rename(No_of_text_records=n)
P <- afinn_ESD[which(afinn_ESD$sentiment == "positive"),2]
N <- afinn_ESD[which(afinn_ESD$sentiment == "negative"),2]
PD <- round(((P - N)/(P + N))*100,digits = 2)
}
if(metric == 2){
P <- afinn_ESD[which(afinn_ESD$sentiment == "positive"),2]
N <- afinn_ESD[which(afinn_ESD$sentiment == "negative"),2]
O <- afinn_ESD[which(afinn_ESD$sentiment == "neutral"),2]
PD <- round((abs(P - N) / (P + N + O))*100,digits = 2)
}
if(metric == 3){
P <- afinn_ESD[which(afinn_ESD$sentiment == "positive"),2]
N <- afinn_ESD[which(afinn_ESD$sentiment == "negative"),2]
O <- afinn_ESD[which(afinn_ESD$sentiment == "neutral"),2]
PD <- round((P / (P + N + O))*100, digits = 2)
}
if(metric == 4){
P <- afinn_ESD[which(afinn_ESD$sentiment == "positive"),2]
N <- afinn_ESD[which(afinn_ESD$sentiment == "negative"),2]
O <- afinn_ESD[which(afinn_ESD$sentiment == "neutral"),2]
PD <- round((N / (P + N + O))*100, digits = 2)
}
}
if(metric == 5){
P <- afinn_ESD[which(afinn_ESD$sentiment == "positive"),2]
N <- afinn_ESD[which(afinn_ESD$sentiment == "negative"),2]
O <- afinn_ESD[which(afinn_ESD$sentiment == "neutral"),2]
PD <- as.numeric(fun(P, N, O))
}
nsim_exp_scores <- c(nsim_exp_scores,
as.numeric(as.character(PD)))
if(quiet == FALSE){
flush.console()
print(paste("No. of simulations completed:", m, sep=","))
}
if(quiet == TRUE){
#do nothing
}
}
return(nsim_exp_scores)
}
#}
results <- opi_impact(textdoc = policing_otd, sec_keywords=covid_keys, metric = 1,
fun = NULL, nsim = 99, alternative="two.sided",
pplot = FALSE, quiet=FALSE)
print(results)
results <- opi_impact(textdoc = policing_otd, sec_keywords=covid_keys, metric = 1,
fun = NULL, nsim = 99, alternative="two.sided",
pplot = TRUE, quiet=FALSE)
results <- opi_impact(textdoc = policing_otd, sec_keywords=covid_keys, metric = 1,
fun = NULL, nsim = 99, alternative="two.sided",
pplot = TRUE, quiet=FALSE)
print(results)
opi_impact <- function(textdoc, sec_keywords=NULL, metric = 1,
fun = NULL, nsim = 99, alternative="two.sided",
pplot = FALSE, quiet=TRUE){ #tweets
#output holder
output <- list()
#check if randomization is too small
if(nsim < 9){
stop("Number of simulation (nsim) is too small!!")
}
if(nsim > 9999){
stop(paste("Consider specifying a smaller",
"number of simulations (nsim)!!", sep=" "))
}
if(is.null(sec_keywords)){
stop(" 'sec_keywords' parameter cannot be 'NULL'!! ")
}
#check any contradiction in tail comparison
if(metric == 1 & alternative %in% c("less", "greater")){
stop(paste("When parameter `metric = 1`, argument",
" `alternative` must be set as 'two.sided'!! "))
}
if(metric %in% c(2:4) & alternative == "two.sided"){
stop(paste('When parameter `metric =` ', metric,
", argument `two.sided` must be set as 'less'!! ", sep=""))
}
#format keywords
sec_keywords <- data.frame(as.character(sec_keywords[,1]))
colnames(sec_keywords) <- "keys"
sec_keywords <-
as.character(sec_keywords %>% map_chr(~ str_c(., collapse = "|")))
#format text records
textdoc <- data.frame(textdoc[,1])
colnames(textdoc) <- "text"
#separate `textdoc` into two:
#'textdoc_keypresent': contains any of the keywords
#'textdoc_keyabsent': contains no keywords
textdoc_keypresent <- data.frame(textdoc) %>%
dplyr::filter(stringr::str_detect(text, sec_keywords, negate=FALSE)) %>%
mutate(keywords = "present")
if(nrow(textdoc_keypresent)==0){
stop(paste("The text record contains NONE any of",
"the secondary keywords!! Operation terminated!!", sep=" "))
}
textdoc_keyabsent <- data.frame(textdoc) %>%
dplyr::filter(stringr::str_detect(text, sec_keywords, negate=TRUE))%>%
mutate(keywords = "absent")
#combine and retain the IDs of text records
#for later joining
textdoc_comb <- rbind(textdoc_keypresent, textdoc_keyabsent)
#create seq_ID
textdoc_comb$ID <- seq.int(nrow(textdoc_comb))
textonly <- data.frame(textdoc_comb$text) #head(textonly)
colnames(textonly) <- "text"
#drop the large text field
textdoc_comb <- textdoc_comb %>%
select(c(keywords, ID))
#compute the OSD and opinion scores
obj_both <- opi_score(textonly, metric = metric, fun = fun)
#extract the score
observed_score <- as.numeric(gsub("\\%", "", obj_both$opiscore))
#extract the OSD
OSD <- obj_both$OSD
#join OSD and the with the pre-processed
OSD_joined <- textdoc_comb %>%
left_join(OSD) %>%
#filter records that do not contain sentiment words
filter(!is.na(sentiment)) %>%
arrange(desc(keywords), sentiment)%>%
select(ID, sentiment, keywords)
#prepare data for Likert plot
#filter neutral
likert_osd <- OSD_joined %>%
#filter(sentiment != "neutral") %>%
dplyr::arrange(keywords, desc(sentiment)) %>%
dplyr::select(-c(ID)) %>%
dplyr::mutate(class = if_else(sentiment == "neutral", paste("neutral", "", sep=""),
paste(paste("key",keywords, sep="."), sentiment, sep="_")))%>%
dplyr::select(class)
#hich(OSD_joined$sentiment == "neutral")
#unique(likert_osd$class)
#plot function here
if(pplot == TRUE){
dev.new(width=8,height=3,noRStudioGD = TRUE)
#lik_p1 <- read.table(file = paste("Likert_Data",PR[m], ".csv", sep="_"), sep=",", head=TRUE)
lik_p1 <- data.frame(likert_osd) %>% mutate_if(is.character,as.factor)
# Make list of ordered factor variables
out <- lapply(lik_p1, function(x) ordered(x, levels = c("key.absent_positive", "key.absent_negative", "neutral", "key.present_negative", "key.present_positive")))
#  Combine into data.frame
res <- do.call( data.frame , out )
# Build plot
likert.options(legend="Classes")
p <- likert(res)
title = "Percentage proportion of classes"
#plot(p, center=3, centered=FALSE) + ggtitle(title)
likert.bar.plot(p, legend="Classes")
}
if(pplot == FALSE){
#do nothing
}
if(quiet == TRUE){
#generate expected scores using `opi_sim` function
expected_scores <- opi_sim(osd_data = OSD_joined,
nsim=nsim,quiet=TRUE)
}
if(quiet == FALSE){
#generate expected scores using `opi_sim` function
expected_scores <- opi_sim(osd_data = OSD_joined,
nsim=nsim,quiet=FALSE)
}
#check if there is contradiction in
#the alternative argument
if(observed_score > 0 & alternative == "less"){
flush.console()
print(paste("Warning: 'Observed score' is positive!!",
"'two.sided' criterion is utilized!"))
alternative <- "two.sided"
}
if(observed_score <= 0 & alternative == "greater"){
flush.console()
print(paste("Warning: 'Observed score' is negative!!",
"'two.sided' criterion is utilized!"))
alternative <- "two.sided"
}
#first, check the alternative argument
#second, check the sign of the observed score.
#third, compute the p-value
if(alternative == "two.sided"){
if(observed_score <= 0){
S <- expected_scores[which(expected_scores <= observed_score)]
S <- length(S)
}
if(observed_score > 0){
S <- expected_scores[which(expected_scores > observed_score)]
S <- length(S)
}
p <- round((S + 1)/(nsim + 1), digits = nchar(nsim))
}
if(alternative == "less"){
S <- expected_scores[which(expected_scores <= observed_score)]
S <- length(S)
p <- round((S + 1)/(nsim + 1), digits = nchar(nsim))
}
if(alternative == "greater"){
S <- expected_scores[which(expected_scores > observed_score)]
S <- length(S)
p <- round((S + 1)/(nsim + 1), digits = nchar(nsim))
}
#preparing final result
S_beat <- S
#significance level
#first, create a table of significance
#nsim=99
ci <- c(95, 97.5, 99, 99.9, 99.99)
v <- c(nsim, ((nsim + 1) - ((nsim + 1) * (ci/100))))
#remove decimal locations
v <- v[v >= 1]
p_loc <- round(v/(nsim+1), digits = nchar(nsim+1))
p_loc <- p_loc[order(p_loc)]
#create list of asterix
aster <- NULL
for(i in 3:1){ #i=3
n <- rep("*", i)
aster <- rbind(aster, paste(n, collapse='' ))
}
aster <- rbind(aster, "'")
p_loc <- data.frame(cbind(p_loc, aster))
colnames(p_loc) <- c("p_loc", "asterisk")
v <- c(v, 0)
v <- v[order(v)]
#where does S falls
int <- findInterval(S_beat, v)
signif <- p_loc[int,2]
signif <- paste(signif, collapse='')
#finally merge col
p_loc <- p_loc %>%
mutate(comb=paste(p_loc, asterisk, sep="")) %>%
dplyr::select(comb)
p_loc <- p_loc[, "comb"]
#collate all results
output$test <- "Test of significance (Randomization testing)"
output$criterion <- alternative
output$exp_summary <- summary(expected_scores)
output$p_table <- knitr::kable(data.frame(cbind(observed_score, S_beat, nsim, p=(S+1)/(nsim+1),   signif)))
output$p_key <- rev(p_loc)
output$p_formula <- "(S_beat + 1)/(nsim + 1)"
return(output)
}
results <- opi_impact(textdoc = policing_otd, sec_keywords=covid_keys, metric = 1,
fun = NULL, nsim = 99, alternative="two.sided",
pplot = TRUE, quiet=FALSE)
print(results)
opi_impact <- function(textdoc, sec_keywords=NULL, metric = 1,
fun = NULL, nsim = 99, alternative="two.sided",
pplot = FALSE, quiet=TRUE){ #tweets
#output holder
output <- list()
#check if randomization is too small
if(nsim < 9){
stop("Number of simulation (nsim) is too small!!")
}
if(nsim > 9999){
stop(paste("Consider specifying a smaller",
"number of simulations (nsim)!!", sep=" "))
}
if(is.null(sec_keywords)){
stop(" 'sec_keywords' parameter cannot be 'NULL'!! ")
}
#check any contradiction in tail comparison
if(metric == 1 & alternative %in% c("less", "greater")){
stop(paste("When parameter `metric = 1`, argument",
" `alternative` must be set as 'two.sided'!! "))
}
if(metric %in% c(2:4) & alternative == "two.sided"){
stop(paste('When parameter `metric =` ', metric,
", argument `two.sided` must be set as 'less'!! ", sep=""))
}
#format keywords
sec_keywords <- data.frame(as.character(sec_keywords[,1]))
colnames(sec_keywords) <- "keys"
sec_keywords <-
as.character(sec_keywords %>% map_chr(~ str_c(., collapse = "|")))
#format text records
textdoc <- data.frame(textdoc[,1])
colnames(textdoc) <- "text"
#separate `textdoc` into two:
#'textdoc_keypresent': contains any of the keywords
#'textdoc_keyabsent': contains no keywords
textdoc_keypresent <- data.frame(textdoc) %>%
dplyr::filter(stringr::str_detect(text, sec_keywords, negate=FALSE)) %>%
mutate(keywords = "present")
if(nrow(textdoc_keypresent)==0){
stop(paste("The text record contains NONE any of",
"the secondary keywords!! Operation terminated!!", sep=" "))
}
textdoc_keyabsent <- data.frame(textdoc) %>%
dplyr::filter(stringr::str_detect(text, sec_keywords, negate=TRUE))%>%
mutate(keywords = "absent")
#combine and retain the IDs of text records
#for later joining
textdoc_comb <- rbind(textdoc_keypresent, textdoc_keyabsent)
#create seq_ID
textdoc_comb$ID <- seq.int(nrow(textdoc_comb))
textonly <- data.frame(textdoc_comb$text) #head(textonly)
colnames(textonly) <- "text"
#drop the large text field
textdoc_comb <- textdoc_comb %>%
select(c(keywords, ID))
#compute the OSD and opinion scores
obj_both <- opi_score(textonly, metric = metric, fun = fun)
#extract the score
observed_score <- as.numeric(gsub("\\%", "", obj_both$opiscore))
#extract the OSD
OSD <- obj_both$OSD
#join OSD and the with the pre-processed
OSD_joined <- textdoc_comb %>%
left_join(OSD) %>%
#filter records that do not contain sentiment words
filter(!is.na(sentiment)) %>%
arrange(desc(keywords), sentiment)%>%
select(ID, sentiment, keywords)
#prepare data for Likert plot
#filter neutral
likert_osd <- OSD_joined %>%
#filter(sentiment != "neutral") %>%
dplyr::arrange(keywords, desc(sentiment)) %>%
dplyr::select(-c(ID)) %>%
dplyr::mutate(class = if_else(sentiment == "neutral", paste("neutral", "", sep=""),
paste(paste("key",keywords, sep="."), sentiment, sep="_")))%>%
dplyr::select(class)
#hich(OSD_joined$sentiment == "neutral")
#unique(likert_osd$class)
#plot function here
if(pplot == TRUE){
dev.new(width=8,height=3,noRStudioGD = TRUE)
#lik_p1 <- read.table(file = paste("Likert_Data",PR[m], ".csv", sep="_"), sep=",", head=TRUE)
lik_p1 <- data.frame(likert_osd) %>% mutate_if(is.character,as.factor)
# Make list of ordered factor variables
out <- lapply(lik_p1, function(x) ordered(x, levels = c("key.absent_positive", "key.absent_negative", "neutral", "key.present_negative", "key.present_positive")))
#  Combine into data.frame
res <- do.call( data.frame , out )
# Build plot
likert.options(legend="Classes")
p <- likert(res)
title = "Percentage proportion of classes"
#plot(p, center=3, centered=FALSE) + ggtitle(title)
pp <- likert.bar.plot(p, legend="Classes")
}
if(pplot == FALSE){
#do nothing
}
if(quiet == TRUE){
#generate expected scores using `opi_sim` function
expected_scores <- opi_sim(osd_data = OSD_joined,
nsim=nsim,quiet=TRUE)
}
if(quiet == FALSE){
#generate expected scores using `opi_sim` function
expected_scores <- opi_sim(osd_data = OSD_joined,
nsim=nsim,quiet=FALSE)
}
#check if there is contradiction in
#the alternative argument
if(observed_score > 0 & alternative == "less"){
flush.console()
print(paste("Warning: 'Observed score' is positive!!",
"'two.sided' criterion is utilized!"))
alternative <- "two.sided"
}
if(observed_score <= 0 & alternative == "greater"){
flush.console()
print(paste("Warning: 'Observed score' is negative!!",
"'two.sided' criterion is utilized!"))
alternative <- "two.sided"
}
#first, check the alternative argument
#second, check the sign of the observed score.
#third, compute the p-value
if(alternative == "two.sided"){
if(observed_score <= 0){
S <- expected_scores[which(expected_scores <= observed_score)]
S <- length(S)
}
if(observed_score > 0){
S <- expected_scores[which(expected_scores > observed_score)]
S <- length(S)
}
p <- round((S + 1)/(nsim + 1), digits = nchar(nsim))
}
if(alternative == "less"){
S <- expected_scores[which(expected_scores <= observed_score)]
S <- length(S)
p <- round((S + 1)/(nsim + 1), digits = nchar(nsim))
}
if(alternative == "greater"){
S <- expected_scores[which(expected_scores > observed_score)]
S <- length(S)
p <- round((S + 1)/(nsim + 1), digits = nchar(nsim))
}
#preparing final result
S_beat <- S
#significance level
#first, create a table of significance
#nsim=99
ci <- c(95, 97.5, 99, 99.9, 99.99)
v <- c(nsim, ((nsim + 1) - ((nsim + 1) * (ci/100))))
#remove decimal locations
v <- v[v >= 1]
p_loc <- round(v/(nsim+1), digits = nchar(nsim+1))
p_loc <- p_loc[order(p_loc)]
#create list of asterix
aster <- NULL
for(i in 3:1){ #i=3
n <- rep("*", i)
aster <- rbind(aster, paste(n, collapse='' ))
}
aster <- rbind(aster, "'")
p_loc <- data.frame(cbind(p_loc, aster))
colnames(p_loc) <- c("p_loc", "asterisk")
v <- c(v, 0)
v <- v[order(v)]
#where does S falls
int <- findInterval(S_beat, v)
signif <- p_loc[int,2]
signif <- paste(signif, collapse='')
#finally merge col
p_loc <- p_loc %>%
mutate(comb=paste(p_loc, asterisk, sep="")) %>%
dplyr::select(comb)
p_loc <- p_loc[, "comb"]
#collate all results
output$test <- "Test of significance (Randomization testing)"
output$criterion <- alternative
output$exp_summary <- summary(expected_scores)
output$p_table <- knitr::kable(data.frame(cbind(observed_score, S_beat, nsim, p=(S+1)/(nsim+1),   signif)))
output$p_key <- rev(p_loc)
output$p_formula <- "(S_beat + 1)/(nsim + 1)"
output$plot <- pp
return(output)
}
results <- opi_impact(textdoc = policing_otd, sec_keywords=covid_keys, metric = 1,
fun = NULL, nsim = 99, alternative="two.sided",
pplot = TRUE, quiet=FALSE)
