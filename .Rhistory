if(m == 5){
img5 <- img
}
if(m == 6){
img6 <- img
}
if(m == 7){
img7 <- img
}
if(m == 8){
img8 <- img
}
if(m == 9){
img9 <- img
}
if(m == 10){
img10 <- img
}
# f <- file.path(tempdir(), paste("img", m, sep=""))
#   ggsave(paste(f, ".png", sep=""))
}
img10
img5
images <- list(img1, img2, img3, img4, img5, img6,
img7, img8,img9,img10)
#a rough way to do facet wrap..
for(m in seq_len(n_grp)){ #m<-1
topn <- data.frame(tf_idf) %>%
filter(groups == m) %>%
slice(tf_idf, 1:n_top)
#topn
par(mar=rep(0.8,4))
img <- data.frame(tf_idf) %>%
filter(groups == m) %>%
slice(tf_idf, 1:n_top) %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf)))+ #cols[3]
geom_col(show.legend = FALSE) +
geom_col(fill=cols2[m],show.legend = FALSE) +
scale_y_discrete(labels = rev(topn$word))+
facet_wrap(~groups, ncol = 2, scales="fixed") +
scale_x_continuous(limits=c(min(tf_idf$tf_idf),max(tf_idf$tf_idf))) +
labs(x = "tf_idf", y=NULL)+
theme_bw()
# theme(axis.title.x=element_blank(),
#       axis.text.x=element_blank(),
#       axis.ticks.x=element_blank())
img
if(m == 1){
img1 <- img
}
if(m == 2){
img2 <- img
}
if(m == 3){
img3 <- img
}
if(m == 4){
img4 <- img
}
if(m == 5){
img5 <- img
}
if(m == 6){
img6 <- img
}
if(m == 7){
img7 <- img
}
if(m == 8){
img8 <- img
}
if(m == 9){
img9 <- img
}
if(m == 10){
img10 <- img
}
# f <- file.path(tempdir(), paste("img", m, sep=""))
#   ggsave(paste(f, ".png", sep=""))
}
images <- list(img1, img2, img3, img4, img5, img6,
img7, img8,img9,img10)
img6
img4
img10
#global variables
aes <- arrange <- collapse <- coord_flip <- desc <- facet_wrap <- filter <- geom_bar <-
group_by <- labs <- mutate <- ntile <- rowname <- scale_alpha_discrete <-
scale_fill_brewer <- select <- stopwords <- text <- text2 <-
tf <- top_n <- ungroup <- word <- wordcloud2 <- img1 <- img2 <-img3 <-
img4 <- img5 <- img6 <- img7 <- img8 <- img9 <- img10 <-
groups <- tibble <- dev.new <- NULL
#a rough way to do facet wrap..
for(m in seq_len(n_grp)){ #m<-1
topn <- data.frame(tf_idf) %>%
filter(groups == m) %>%
slice(tf_idf, 1:n_top)
#topn
par(mar=rep(0.8,4))
img <- data.frame(tf_idf) %>%
filter(groups == m) %>%
slice(tf_idf, 1:n_top) %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf)))+ #cols[3]
geom_col(show.legend = FALSE) +
geom_col(fill=cols2[m],show.legend = FALSE) +
scale_y_discrete(labels = rev(topn$word))+
facet_wrap(~groups, ncol = 2, scales="fixed") +
scale_x_continuous(limits=c(min(tf_idf$tf_idf),max(tf_idf$tf_idf))) +
labs(x = "tf_idf", y=NULL)+
theme_bw()
# theme(axis.title.x=element_blank(),
#       axis.text.x=element_blank(),
#       axis.ticks.x=element_blank())
img
if(m == 1){
img1 <- img
}
if(m == 2){
img2 <- img
}
if(m == 3){
img3 <- img
}
if(m == 4){
img4 <- img
}
if(m == 5){
img5 <- img
}
if(m == 6){
img6 <- img
}
if(m == 7){
img7 <- img
}
if(m == 8){
img8 <- img
}
if(m == 9){
img9 <- img
}
if(m == 10){
img10 <- img
}
# f <- file.path(tempdir(), paste("img", m, sep=""))
#   ggsave(paste(f, ".png", sep=""))
}
images <- list(img1, img2, img3, img4, img5, img6,
img7, img8,img9,img10)
images
images
img1
images <- list(img1=img1, img2=img2, img3=img3,
img4=img4, img5=img5, img6=img6,
img7=img7, img8=img8,img9=img9,img10=img10)
images
ggarrange(
#bxp, dp, labels = c("A", "B"),
images,
common.legend = FALSE, ncol=2, legend = "right"
)
library(ggpubr)
install.packages("broom")
install.packages("broom")
library(broom)
library(broom)
plot_grid(images)
library(ggplot2)
ggplot2::plot_grid
library(cowplot)
plot_grid(images)
images[1]
plot_grid(images[1])
plot_grid(images[1:5])
plot_grid(plotlist=images)
plot_grid(plotlist=images, cols = 2)
images
which(images == "NULL")
images <- images[which(images != "NULL")]
images
plt <- plot_grid(plotlist=images, cols = 2)
plt <- plot_grid(plotlist=images, cols = 2)
plt <- plot_grid(plotlist=images, ncol = 2)
plt
#a rough way to do facet wrap..
for(m in seq_len(n_grp)){ #m<-1
topn <- data.frame(tf_idf) %>%
filter(groups == m) %>%
slice(tf_idf, 1:n_top)
#topn
par(mar=rep(0.8,4))
img <- data.frame(tf_idf) %>%
filter(groups == m) %>%
mutate(groups = paste("Group",groups,sep=" "))%>%
slice(tf_idf, 1:n_top) %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf)))+ #cols[3]
geom_col(show.legend = FALSE) +
geom_col(fill=cols2[m],show.legend = FALSE) +
scale_y_discrete(labels = rev(topn$word))+
facet_wrap(~groups, ncol = 2, scales="fixed") +
scale_x_continuous(limits=c(min(tf_idf$tf_idf),max(tf_idf$tf_idf))) +
labs(x = "tf_idf", y=NULL)+
theme_bw()
# theme(axis.title.x=element_blank(),
#       axis.text.x=element_blank(),
#       axis.ticks.x=element_blank())
img
if(m == 1){
img1 <- img
}
if(m == 2){
img2 <- img
}
if(m == 3){
img3 <- img
}
if(m == 4){
img4 <- img
}
if(m == 5){
img5 <- img
}
if(m == 6){
img6 <- img
}
if(m == 7){
img7 <- img
}
if(m == 8){
img8 <- img
}
if(m == 9){
img9 <- img
}
if(m == 10){
img10 <- img
}
# f <- file.path(tempdir(), paste("img", m, sep=""))
#   ggsave(paste(f, ".png", sep=""))
}
images <- list(img1=img1, img2=img2, img3=img3,
img4=img4, img5=img5, img6=img6,
img7=img7, img8=img8,img9=img9,img10=img10)
images <- images[which(images != "NULL")]
plt <- plot_grid(plotlist=images, ncol = 2)
plt
tfidf_plot <- plot_grid(plotlist=images, ncol = 2)
tf_plot
tf <- data.frame(tf) %>%
rename(freq=c)
row.names(tf) <- tf$word
#calculate 'tf' across all groups & 'tf_idf' value per groups
tf <- tokenize_series %>%
select(word)%>%
group_by(word)%>%
summarise(c=n())%>%
#bind_tf_idf(word, groups, c) %>%
arrange(desc(c))
tf <- data.frame(tf) %>%
rename(freq=c)
row.names(tf) <- tf$word
#use only the top 1000 words
tf_plot <- wordcloud2(data=tf[1:500,], size = 0.7, shape = 'rectangle')
wordcloud2(data=tf[1:500,], size = 0.7, shape = 'rectangle')
library(wordcloud2)
#use only the top 1000 words
tf_plot <- wordcloud2(data=tf[1:500,], size = 0.7, shape = 'rectangle')
tf_plot
library(roxygen2)
library(ggplot2)
getwd()
load("~/GitHub/opitools/data/covid_keys.rda")
covid_keys
keys <- c("board","sign", "assist", "map", "direction", "display")
write.table(keys, file="C:/Users/monsu/Desktop/piccadilly/signage_keys.csv", sep=",", row.names = F)
signage_keys2 <- read.table(file="C:/Users/monsu/Desktop/piccadilly/signage_keys2.csv", sep=",", head=TRUE)
write.table(keys, file="C:/Users/monsu/Desktop/piccadilly/signage_keys2.csv", sep=",", row.names = F)
signage_keys2 <- read.table(file="C:/Users/monsu/Desktop/piccadilly/signage_keys2.csv", sep=",", head=TRUE)
signage_keys2
keys <- data.frame(keys=c("board","sign", "assist", "map", "direction", "display"))
keys
write.table(keys, file="C:/Users/monsu/Desktop/piccadilly/signage_keys2.csv", sep=",", row.names = F)
signage_keys2 <- read.table(file="C:/Users/monsu/Desktop/piccadilly/signage_keys2.csv", sep=",", head=TRUE)
signage_keys2
saveRDS(signage_keys2, "C:/Users/monsu/Desktop/piccadilly/signage_keys2.rda", sep=",")
save(signage_keys2, "C:/Users/monsu/Desktop/piccadilly/signage_keys2.rda")
saveRDS(signage_keys2, "C:/Users/monsu/Desktop/piccadilly/signage_keys2.rda")
saveRDS(signage_keys2, "C:/Users/monsu/Desktop/piccadilly/signage_keys2.rda", ascii = TRUE)
saveRDS(signage_keys2, "C:/Users/monsu/Desktop/piccadilly/signage_keys2.rda", version = 1)
saveRDS(signage_keys2, "C:/Users/monsu/Desktop/piccadilly/signage_keys2.rda", version = 2)
saveRDS(signage_keys2, "C:/Users/monsu/Desktop/piccadilly/signage_keys2.rda", version = 3)
load(file="C:/Users/monsu/Documents/GitHub/opitools/data/covid_keys.rda")
mod = c("board","sign", "assist", "map", "direction", "display")
save(mod, file = "mymodel.rda")
getwd()
mod
mod = data.frame(c("board","sign", "assist", "map", "direction", "display"))
save(mod, file = "mymodel.rda")
data.frame(c("board","sign", "assist", "map", "direction", "display"))
mod = data.frame(keys=c("board","sign", "assist", "map", "direction", "display"))
save(mod, file = "mymodel.rda")
signage_keys = data.frame(keys=c("board","sign", "assist", "map", "direction", "display"))
save(signage_keys, file = "signage_keys.rda")
facility_keys = data.frame(keys=c("bank", "atm", "toilet", "ramp", "bench", "chair", "stair", "lift", "elevator", "trolley", "floor", "ticket machine", "Waiting room", "pay phone", "postbox"))
facility_keys = data.frame(keys=c("bank", "atm", "toilet", "ramp", "bench", "chair", "stair", "lift", "elevator", "trolley", "floor", "ticket machine", "Waiting room", "pay phone", "postbox"))
save(facility_keys, file = "facility_keys.rda")
head(reviews_otd)
library(dplyr)
library(stringr)
my_txt <- read.csv2("C:/Users/monsu/Desktop/piccadilly/reviews_piccaddily.txt", head=FALSE)
nrow(my_txt)
head(my_txt)
txt <- data.frame(text=my_txt)
colnames(txt) <- "text"
txt <- txt %>%
mutate(len=str_length(text))
head(txt)
#set threshold as 80
reviews_otd <- txt %>%
dplyr::filter(len >= 80)%>%
mutate(id = row_number())%>%
dplyr::select(text)
head(reviews_otd)
nrow(reviews_otd)
reviews_otd = data.frame(text=reviews_otd))
reviews_otd = data.frame(text=reviews_otd)
head(reviews_otd)
save(reviews_otd, file = "reviews_otd.rda")
library(opitools)
facility_keys
signage_keys
output <- opi_impact(textdoc = policing_otd,
sec_keywords=covid_keys, metric = 1,
fun = NULL, nsim = 99, alternative="two.sided",
quiet=TRUE)
#check output variables
print(output)
#to access the pvalue
output$pvalue
#Accessing facility-related keywords
output <- opi_impact(textdoc = reviews_otd,
sec_keywords=facility_keys, metric = 1,
fun = NULL, nsim = 99, alternative="two.sided",
quiet=TRUE)
#check output variables
print(output)
#to access the pvalue
output$pvalue
#Accessing signage-related keywords
output <- opi_impact(textdoc = reviews_otd,
sec_keywords=signage_keys, metric = 1,
fun = NULL, nsim = 99, alternative="two.sided",
quiet=TRUE)
#check output variables
print(output)
#to access the pvalue
output$pvalue
score <- opi_score(textdoc = reviews_otd,
metric = 1, fun = NULL)
score
exp_score <- opi_sim(reviews_otd, nsim=99, metric = 1,
fun = NULL, quiet=TRUE)
reviews_otd
reviews_otd
exp_score <- opi_sim(reviews_otd, nsim=99, metric = 1,
fun = NULL, quiet=TRUE)
library(opitools)
reviews_otd
facility_keys
output <- opi_impact(textdoc = reviews_otd,
sec_keywords=facility_keys, metric = 1,
fun = NULL, nsim = 99, alternative="two.sided",
quiet=TRUE)
output
signage_keys
output <- opi_impact(textdoc = reviews_otd,
sec_keywords=signage_keys, metric = 1,
fun = NULL, nsim = 99, alternative="two.sided",
quiet=TRUE)
output
load("~/GitHub/opitools/R/sysdata.rda")
sysdata
signage_keys
reviews_dtd <- reviews_otd
head(reviews_dtd)
C:\Users\monsu\Documents\GitHub/opitools/data/
save(reviews_dtd, file = "C:/Users/monsu/Documents/GitHub/opitools/data/reviews_dtd.rda")
save(reviews_dtd, file = "C:/Users/monsu/Documents/GitHub/opitools/data/reviews_dtd.rda")
policing_dtd <- policing_otd
save(policing_dtd, file = "C:/Users/monsu/Documents/GitHub/opitools/data/policing_dtd.rda")
tweets_dat
citation(package = "wordcloud2", lib.loc = NULL)
library(opitools)
dat1 <- data("policing_dtd")
output1 <- word_importance(textdoc = policing_dtd, metric= "tf", n_top=5)
output1
output1$plot
output1$plot
dev.new()
output1$plot
print(output1$plot)
textdoc=policing_dtd
metric = "tf"
n_top=5
output <- list()
#global variables
aes <- arrange <- collapse <- coord_flip <- desc <- facet_wrap <- filter <- geom_bar <-
group_by <- labs <- mutate <- ntile <- rowname <- scale_alpha_discrete <-
scale_fill_brewer <- select <- stopwords <- text <- text2 <-
tf <- top_n <- ungroup <- word <- wordcloud2 <- img1 <- img2 <-img3 <-
img4 <- img5 <- img6 <- img7 <- img8 <- img9 <- img10 <- img11 <-
img12 <- img13 <- img14 <- img15 <- img16 <- img17 <- img18 <- img19 <-
img20 <- groups <- tibble <- dev.new <- gg_color_hue <- hcl <-
slice <- par <- scale_y_discrete <- scale_x_continuous <-
theme_bw <- NULL
dim(textdoc)[1] < 20
dim(textdoc)[1] > 10000000
length(dim(textdoc)) != 2 & (dim(textdoc)[2] != 1 | dim(textdoc)[2] != 2)
nr <- dim(textdoc)[1] #no. of rows
nc <- dim(textdoc)[2] #no. of columns
nc == 1
dat <- as.data.frame(textdoc)
#create interval to determine the number of arbitrary group
#to impose on the document.
no_of_grps <- c(5, 10, 15, 20)
#abitr_label <- data.frame(rbind(c(20, 200),c(201, 1000),
#c(1001, 10000), c(10001, 10000000)))
abit_label <- c(20, 200, 1000, 10000, 10000000)
#number of arbitrary groups
n_grp <- no_of_grps[findInterval(nr, abit_label)]
#determine where data length fall in the
series <- tibble()
series <- tibble(text = as.character(dat[,1]))%>%
tibble::rownames_to_column() #append rownames to the data
series$groups <- ntile(as.numeric(series$rowname), n_grp)
series <- series %>%
select(-c(rowname))
nc == 2
#tokenize
tokenize_series <- series %>%
group_by(groups)%>%
#paste(text, collapse = " ")
summarise(text2 = paste(text, collapse=" "))%>%
rename(text=text2)%>%
unnest_tokens(word, text) #%>%
library(tidytext)
#tokenize
tokenize_series <- series %>%
group_by(groups)%>%
#paste(text, collapse = " ")
summarise(text2 = paste(text, collapse=" "))%>%
rename(text=text2)%>%
unnest_tokens(word, text) #%>%
#removing stopwords
tokenize_series <- tokenize_series[!tokenize_series$word %in% stopwords("english"),]
library(tidytext)
library(tm)
library(tidytext)
library(wordcloud2)
library(dplyr)
library(cowplot)
library(forcats)
library(ggplot2)
#removing stopwords
tokenize_series <- tokenize_series[!tokenize_series$word %in% stopwords("english"),]
#calculate 'tf' across all groups & 'tf_idf' value per groups
tf <- tokenize_series %>%
select(word)%>%
group_by(word)%>%
summarise(c=n())%>%
#bind_tf_idf(word, groups, c) %>%
arrange(desc(c))
tf
tf_idf <- tokenize_series %>%
group_by(word, groups)%>%
summarise(c=n())%>%
bind_tf_idf(word, groups, c) %>%
arrange(desc(tf_idf))%>%
group_by(groups)%>%
#remove duplicate
filter(!duplicated(word))
tf_idf
mode(tf_idf$groups)
tf_idf$groups <- as.character(tf_idf$groups)
if(metric == "tf"){
tf <- data.frame(tf) %>%
rename(freq=c)
row.names(tf) <- tf$word
#use only the top 1000 words
tf_plot <- wordcloud2(data=tf[1:500,], size = 0.7, shape = 'rectangle')
}
tf_plot
metric == "tf"
tf <- data.frame(tf) %>%
rename(freq=c)
tf <- data.frame(tf) %>%
rename(freq=c)
row.names(tf) <- tf$word
#use only the top 1000 words
#calculate 'tf' across all groups & 'tf_idf' value per groups
tf <- tokenize_series %>%
select(word)%>%
group_by(word)%>%
summarise(c=n())%>%
#bind_tf_idf(word, groups, c) %>%
arrange(desc(c))
tf <- data.frame(tf) %>%
rename(freq=c)
row.names(tf) <- tf$word
#use only the top 1000 words
tf_plot <- wordcloud2(data=tf[1:500,], size = 0.7, shape = 'rectangle')
wordcloud2(data=tf[1:500,], size = 0.7, shape = 'rectangle')
