"records per group", sep=" ")
dataframe(cbind(c(20, 200), c(201, 1000),
c(1001, 10000), c(10000, 10000000000)))
data.frame(cbind(c(20, 200), c(201, 1000),
c(1001, 10000), c(10000, 10000000000)))
abit_group <- c(20, 200, 1000,
10000, 10000, 10000000000)
abit_group
abit_group <- c(20, 200, 1000,
10000, 10000, 10000000000)
abit_group
dat <- as.data.frame(textdoc)
dat
dat <- as.data.frame(textdoc)
nr
data <- data.frame(ID = 1:4,
time.s = c(1,1,2,2),
time.e = c(2,4,3,4))
data
data.table::between(1, data.frame$time.s, data.frame$time.e)
data <- data.frame(ID = 1:4,
time.s = c(1,1,2,2),
time.e = c(2,4,3,4))
data.table::between(1, data$time.s, data$time.e)
data.table::between(3, data$time.s, data$time.e)
data.frame(rbind(c(20, 200),c(201, 1000), c(1001, 10000), c(10001, 10000000)))
#create interval to determine number of arbitrary group
#to impose on a document.
no_of_grps <- c(5, 10, 15, 20)
abit_label <- data.frame(rbind(c(20, 200),c(201, 1000),
c(1001, 10000), c(10001, 10000000)))
#join
abit_label <- cbind(abit_label, no_of_grps)
abit_label
data.table::between(3, abit_label$X1, abit_label$X2)
data.table::between(nr, abit_label$X1, abit_label$X2)
nr
abit_label[which(data.table::between(nr, abit_label$X1, abit_label$X2)),3]
abit_label[which(data.table::between(nr,
abit_label$X1, abit_label$X2))
,c(no_of_grps)]
abit_label[which(data.table::between(nr,
abit_label$X1, abit_label$X2))
,`no_of_grps`]
n_grp <- abit_label[which(data.table::between(nr,
abit_label$X1, abit_label$X2))
,3]
n_grp
series <- tibble()
series <- tibble(text = as.character(dat[,1]))%>%
tibble::rownames_to_column() #append rownames to the data
series$group <- ntile(as.numeric(series$rowname), n_grp)
series <- series %>%
select(-c(rowname))
nc == 2
tf_idf <- function(textdoc, n_top=10, showplot=FALSE){
output <- list()
#global variables
aes <- arrange <- collapse <- coord_flip <- desc <- facet_wrap <- filter <- geom_bar <- group
group_by <- labs <- mutate <- ntile <- rowname <- scale_alpha_discrete <-
scale_fill_brewer <- select <- stopwords <- text <- tf <- top_n <- tweets <- ungroup <- word <-
group <- dev.new <- NULL
#if the length of document is too small
if(dim(textdoc)[1] < 20){
stop(paste("Length of document is too small!!",
"The minimum document length is 20!",
"Process terminated!!", sep = " "))
}
#if the length of document is too large
if(dim(textdoc)[1] > 10000000){
stop(paste("Length of document is too large!!",
"The maximum document length is 10 million records!!",
"Process terminated!!", sep = " "))
}
#if a dataframe of more than two column is supplied
if(length(dim(textdoc)) != 2 & (dim(textdoc)[2] != 1 | dim(textdoc)[2] != 2)){
stop("Input data needs to be a dataframe containing 1 or 2 columns")
}
nr <- dim(textdoc)[1] #no. of rows
nc <- dim(textdoc)[2] #no. of columns
#if there are no groupings in the text document,
#create an arbitrary group
if(nc == 1){
dat <- as.data.frame(textdoc)
#create interval to determine number of arbitrary group
#to impose on a document.
no_of_grps <- c(5, 10, 15, 20)
abit_label <- data.frame(rbind(c(20, 200),c(201, 1000),
c(1001, 10000), c(10001, 10000000)))
#join
abit_label <- cbind(abit_label, no_of_grps)
#determine where data length fall in the
#intervals
data <- data.frame(ID = 1:4,
time.s = c(1,1,2,2),
time.e = c(2,4,3,4))
n_grp <- abit_label[which(data.table::between(nr,
abit_label$X1, abit_label$X2))
,3]
series <- tibble()
series <- tibble(text = as.character(dat[,1]))%>%
tibble::rownames_to_column() #append rownames to the data
series$group <- ntile(as.numeric(series$rowname), n_grp)
series <- series %>%
select(-c(rowname))
}
#if there are groupings in the document,
#check that there are at least 20 text records
#per group
#groups
if(nc == 2){
dat <- as.data.frame(textdoc)
series <- tibble()
series <- tibble(text = as.character(dat[,1]), group = dat[,2])
groups <- unique(as.character(dat[,2]))
#if groups are less than 4, stop
#if greater or equal to 4, okay
if(length(groups) <= 3){
stop(paste("The number of groups in the text document",
"should be greater than 3!!",
"And ensure that there are at least 20 text",
"records per group", sep=" "))
}
}
#tokenize
tokenize_series <- series %>%
group_by(group)%>%
collapse(text, sep= " ")%>%
unnest_tokens(word, text) #%>%
#removing stopwords
tokenize_series <- tokenize_series[!tokenize_series$word %in% stopwords("english"),]
#calculate tf_idf value per groups
tf_idf <- tokenize_series %>%
group_by(word, group)%>%
mutate(c=n())%>%
bind_tf_idf(word, group, c) %>%
arrange(desc(tf_idf))%>%
group_by(group)%>%
#remove duplicate
filter(!duplicated(word))
#tf_idf[which(tf_idf$group==7),]
mode(tf_idf$group)
tf_idf$group <- as.character(tf_idf$group)
#print results
output[1] <- list(tf_idf)
#show plot
if(showplot == TRUE){
dev.new()
plt <- tf_idf %>%
arrange(desc(tf_idf)) %>%
#arrange(desc(tf)) %>%
mutate(
groups = factor(group, levels = unique(group))) %>%
group_by(group) %>%
#top_n(10, wt = tf_idf) %>%
top_n(n_top, wt = tf_idf) %>%
ungroup() %>%
#ggplot(aes(word, tf_idf, fill = Regions)) +
ggplot(aes(word, tf, fill = groups)) +
geom_bar(stat = "identity", alpha = .8, show.legend = FALSE) +
labs(title = "",
x = NULL, y = "tf-idf") +
facet_wrap(~groups, ncol = 2, scales = "free") +
scale_alpha_discrete(range = c(0.4,1)) +
scale_fill_brewer(palette = "Set1"
, name = "groups")+
coord_flip()
}
#if false, do nothing
if(showplot == FALSE){
plt <- "Plot disabled"
#do nothings
}
output[2] <- plt
return(output)
}
tf_idf(textdoc = tweets, n_top=10, showplot=FALSE)
traceback()
textdoc
output <- list()
#global variables
aes <- arrange <- collapse <- coord_flip <- desc <- facet_wrap <- filter <- geom_bar <- group
group_by <- labs <- mutate <- ntile <- rowname <- scale_alpha_discrete <-
scale_fill_brewer <- select <- stopwords <- text <- tf <- top_n <- tweets <- ungroup <- word <-
group <- dev.new <- NULL
dim(textdoc)[1] < 20
dim(textdoc)[1] > 10000000
length(dim(textdoc)) != 2 & (dim(textdoc)[2] != 1 | dim(textdoc)[2] != 2)
nr <- dim(textdoc)[1] #no. of rows
nc <- dim(textdoc)[2] #no. of columns
nc == 1
nc == 2
dat <- as.data.frame(textdoc)
series <- tibble()
series <- tibble(text = as.character(dat[,1]), group = dat[,2])
groups <- unique(as.character(dat[,2]))
groups
length(groups) <= 3
tf_idf <- function(textdoc, n_top=10, showplot=FALSE){
output <- list()
#global variables
aes <- arrange <- collapse <- coord_flip <- desc <- facet_wrap <- filter <- geom_bar <- group
group_by <- labs <- mutate <- ntile <- rowname <- scale_alpha_discrete <-
scale_fill_brewer <- select <- stopwords <- text <- tf <- top_n <- tweets <- ungroup <- word <-
group <- dev.new <- NULL
#if the length of document is too small
if(dim(textdoc)[1] < 20){
stop(paste("Length of document is too small!!",
"The minimum document length is 20!",
"Process terminated!!", sep = " "))
}
#if the length of document is too large
if(dim(textdoc)[1] > 10000000){
stop(paste("Length of document is too large!!",
"The maximum document length is 10 million records!!",
"Process terminated!!", sep = " "))
}
#if a dataframe of more than two column is supplied
if(length(dim(textdoc)) != 2 & (dim(textdoc)[2] != 1 | dim(textdoc)[2] != 2)){
stop("Input data needs to be a dataframe containing 1 or 2 columns")
}
nr <- dim(textdoc)[1] #no. of rows
nc <- dim(textdoc)[2] #no. of columns
#if there are no groupings in the text document,
#create an arbitrary group
if(nc == 1){
dat <- as.data.frame(textdoc)
#create interval to determine number of arbitrary group
#to impose on a document.
no_of_grps <- c(5, 10, 15, 20)
abit_label <- data.frame(rbind(c(20, 200),c(201, 1000),
c(1001, 10000), c(10001, 10000000)))
#join
abit_label <- cbind(abit_label, no_of_grps)
#determine where data length fall in the
#intervals
data <- data.frame(ID = 1:4,
time.s = c(1,1,2,2),
time.e = c(2,4,3,4))
n_grp <- abit_label[which(data.table::between(nr,
abit_label$X1, abit_label$X2))
,3]
series <- tibble()
series <- tibble(text = as.character(dat[,1]))%>%
tibble::rownames_to_column() #append rownames to the data
series$group <- ntile(as.numeric(series$rowname), n_grp)
series <- series %>%
select(-c(rowname))
}
#if there are groupings in the document,
#check that there are at least 20 text records
#per group
#groups
if(nc == 2){
dat <- as.data.frame(textdoc)
series <- tibble()
series <- tibble(text = as.character(dat[,1]), group = dat[,2])
groups <- unique(as.character(dat[,2]))
#if groups are less than 4, stop
#if greater or equal to 4, okay
if(length(groups) <= 3){
stop(paste("The number of groups in the text document",
"should be greater than 3!!",
"And ensure that there are at least 20 text",
"records per group", sep=" "))
}
}
#tokenize
tokenize_series <- series %>%
group_by(groups)%>%
collapse(text, sep= " ")%>%
unnest_tokens(word, text) #%>%
#removing stopwords
tokenize_series <- tokenize_series[!tokenize_series$word %in% stopwords("english"),]
#calculate tf_idf value per groups
tf_idf <- tokenize_series %>%
group_by(word, groups)%>%
mutate(c=n())%>%
bind_tf_idf(word, groups, c) %>%
arrange(desc(tf_idf))%>%
group_by(groups)%>%
#remove duplicate
filter(!duplicated(word))
#tf_idf[which(tf_idf$group==7),]
mode(tf_idf$groups)
tf_idf$groups <- as.character(tf_idf$groups)
#print results
output[1] <- list(tf_idf)
#show plot
if(showplot == TRUE){
dev.new()
plt <- tf_idf %>%
arrange(desc(tf_idf)) %>%
#arrange(desc(tf)) %>%
mutate(
groups = factor(groups, levels = unique(groups))) %>%
group_by(group) %>%
#top_n(10, wt = tf_idf) %>%
top_n(n_top, wt = tf_idf) %>%
ungroup() %>%
#ggplot(aes(word, tf_idf, fill = Regions)) +
ggplot(aes(word, tf, fill = groups)) +
geom_bar(stat = "identity", alpha = .8, show.legend = FALSE) +
labs(title = "",
x = NULL, y = "tf-idf") +
facet_wrap(~groups, ncol = 2, scales = "free") +
scale_alpha_discrete(range = c(0.4,1)) +
scale_fill_brewer(palette = "Set1"
, name = "groups")+
coord_flip()
flush.console()
print(plt)
}
#if false, do nothing
if(showplot == FALSE){
#do nothings
}
output[2] <- plt
return(output)
}
tf_idf(textdoc = tweets, n_top=10, showplot=FALSE)
output <- list()
#global variables
aes <- arrange <- collapse <- coord_flip <- desc <- facet_wrap <- filter <- geom_bar <- group
group_by <- labs <- mutate <- ntile <- rowname <- scale_alpha_discrete <-
scale_fill_brewer <- select <- stopwords <- text <- tf <- top_n <- tweets <- ungroup <- word <-
group <- dev.new <- NULL
dim(textdoc)[1] < 20
dim(textdoc)
dim(textdoc)[1]
textdoc = tweets
textdoc
tweets
tf_idf <- function(textdoc, n_top=10, showplot=FALSE){
output <- list()
#global variables
aes <- arrange <- collapse <- coord_flip <- desc <- facet_wrap <- filter <- geom_bar <- group
group_by <- labs <- mutate <- ntile <- rowname <- scale_alpha_discrete <-
scale_fill_brewer <- select <- stopwords <- text <- tf <- top_n <- tweets <- ungroup <- word <-
groups <- dev.new <- NULL
#if the length of document is too small
if(dim(textdoc)[1] < 20){
stop(paste("Length of document is too small!!",
"The minimum document length is 20!",
"Process terminated!!", sep = " "))
}
#if the length of document is too large
if(dim(textdoc)[1] > 10000000){
stop(paste("Length of document is too large!!",
"The maximum document length is 10 million records!!",
"Process terminated!!", sep = " "))
}
#if a dataframe of more than two column is supplied
if(length(dim(textdoc)) != 2 & (dim(textdoc)[2] != 1 | dim(textdoc)[2] != 2)){
stop("Input data needs to be a dataframe containing 1 or 2 columns")
}
nr <- dim(textdoc)[1] #no. of rows
nc <- dim(textdoc)[2] #no. of columns
#if there are no groupings in the text document,
#create an arbitrary group
if(nc == 1){
dat <- as.data.frame(textdoc)
#create interval to determine number of arbitrary group
#to impose on a document.
no_of_grps <- c(5, 10, 15, 20)
abit_label <- data.frame(rbind(c(20, 200),c(201, 1000),
c(1001, 10000), c(10001, 10000000)))
#join
abit_label <- cbind(abit_label, no_of_grps)
#determine where data length fall in the
#intervals
data <- data.frame(ID = 1:4,
time.s = c(1,1,2,2),
time.e = c(2,4,3,4))
n_grp <- abit_label[which(data.table::between(nr,
abit_label$X1, abit_label$X2))
,3]
series <- tibble()
series <- tibble(text = as.character(dat[,1]))%>%
tibble::rownames_to_column() #append rownames to the data
series$groups <- ntile(as.numeric(series$rowname), n_grp)
series <- series %>%
select(-c(rowname))
}
#if there are groupings in the document,
#check that there are at least 20 text records
#per group
#groups
if(nc == 2){
dat <- as.data.frame(textdoc)
series <- tibble()
series <- tibble(text = as.character(dat[,1]), groups = dat[,2])
groups <- unique(as.character(dat[,2]))
#if groups are less than 4, stop
#if greater or equal to 4, okay
if(length(groups) <= 3){
stop(paste("The number of groups in the text document",
"should be greater than 3!!",
"And ensure that there are at least 20 text",
"records per group", sep=" "))
}
}
#tokenize
tokenize_series <- series %>%
group_by(groups)%>%
collapse(text, sep= " ")%>%
unnest_tokens(word, text) #%>%
#removing stopwords
tokenize_series <- tokenize_series[!tokenize_series$word %in% stopwords("english"),]
#calculate tf_idf value per groups
tf_idf <- tokenize_series %>%
group_by(word, groups)%>%
mutate(c=n())%>%
bind_tf_idf(word, groups, c) %>%
arrange(desc(tf_idf))%>%
group_by(groups)%>%
#remove duplicate
filter(!duplicated(word))
#tf_idf[which(tf_idf$group==7),]
mode(tf_idf$groups)
tf_idf$groups <- as.character(tf_idf$groups)
#print results
output[1] <- list(tf_idf)
#show plot
if(showplot == TRUE){
dev.new()
plt <- tf_idf %>%
arrange(desc(tf_idf)) %>%
#arrange(desc(tf)) %>%
mutate(
groups = factor(groups, levels = unique(groups))) %>%
group_by(groups) %>%
#top_n(10, wt = tf_idf) %>%
top_n(n_top, wt = tf_idf) %>%
ungroup() %>%
#ggplot(aes(word, tf_idf, fill = Regions)) +
ggplot(aes(word, tf, fill = groups)) +
geom_bar(stat = "identity", alpha = .8, show.legend = FALSE) +
labs(title = "",
x = NULL, y = "tf-idf") +
facet_wrap(~groups, ncol = 2, scales = "free") +
scale_alpha_discrete(range = c(0.4,1)) +
scale_fill_brewer(palette = "Set1"
, name = "groups")+
coord_flip()
flush.console()
print(plt)
}
#if false, do nothing
if(showplot == FALSE){
#do nothings
}
output[2] <- plt
return(output)
}
tf_idf(textdoc = tweets, n_top=10, showplot=FALSE)
tweets
library(opitools)
dim(policing_otd)
word_distrib(textdoc = policing_otd)
word_distrib(textdoc = policing_otd)
tweets
library(opitools)
dim(tweets)
tweets
rm(list=ls())
tweets
plt = word_distrib(textdoc = tweets)
library(opitools)
library(opitools)
library(opitools)
library(roxygen2)
library(opitools)
library(opitools)
library(opitools)
library(opitools)
library(opitools)
dim(tweets)
tweets_dat <- tweets[,1]
plt = word_distrib(textdoc = tweets)
tweets
tweets[,1]
tweets_dat <- tweets[,1]
word_distrib(textdoc = tweets_dat)
dim(tweets_dat)
tweets_dat <- tweets[,1]
tweets_dat
length(tweets_dat)
data.frame(tweets_dat)
dim(data.frame(tweets_dat))
dim(as.data.frame(tweets_dat))
x <- 2:18
v <- c(5, 10, 15) # create two bins [5,10) and [10,15)
x
v
findInterval(x, v)
x <- 2
v <- c(5, 10, 15)
cbind(x, findInterval(x, v))
nr
nr = 1001
no_of_grps <- c(5, 10, 15, 20)
#abit_label <- data.frame(rbind(c(20, 200),c(201, 1000),
#c(1001, 10000), c(10001, 10000000)))
abit_label <- c(20, 200, 1000, 10000, 10000000)
abit_label
findInterval(nr, abit_label)
#join
n_grp <- no_of_grps[findInterval(nr, abit_label)]
n_grp
library(opitools)
system("R CMD Rd2pdf . --title = Package opitools --output=./opitools_user_manual.pdf --force --no-clean --internals")
