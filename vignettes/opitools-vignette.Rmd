---
title: "An Opinion Analytical Tool for Big Text Document - A User Guide"

author: |
  | `Author:`
  | `Adepeju, M.`
  | `Big Data Centre, Manchester Metropolitan University, Manchester, M15 6BH`
  
date: |
  | `Date:`
  | ``r Sys.Date()``

output:
  html_vignette
  
#output:
  #pdf_document: default
  
#dev: png
#output:
  #word_document: default
  #always_allow_html: yes
#  pdf_document: default
always_allow_html: yes
#fig_caption: yes
bibliography: references.bib

abstract: The development of `'opitools'` is instigated by the lack of tools for performing opinion impact analysis of a digital text document (DTD). The package includes a number of interrelated functions for exploring and analyzing text records towards the completion of opinion impact analysis of a digital text document (DTD). The utility of `Opitools` is demonstrated with examples from the law enforcement, transport and political domains.

vignette: >
  %\VignetteIndexEntry{A guide to using 'opitools' package for opinion and its impacts analysis}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

<style type="text/css">

h1.title {
  font-size: 26px;
  line-height: 130%;
  color: Black;
  text-align: center;
}

h2.subtitle {
  font-size: 13px;
  line-height: 120%;
  color: Black;
  text-align: center;
}

h4.author { /* Header 4 - and the author and data headers use this too  */
  font-size: 17px;
  font-family: "Arial";
  color: Black;
  text-align: center;
}
h4.date { /* Header 4 - and the author and data headers use this too  */
  font-size: 17px;
  font-family: "Arial", Times, serif;
  color: Black;
  text-align: center;
}

h4.abstract { /* Header 4 - and the author and data headers use this too  */
  font-size: 10px;
  font-family: "Arial", Times, serif;
  color: black;
  text-align: center;
}

h4.institute{ /* Header 4 - and the author and data headers use this too  */
  font-size: 10px;
  font-family: "Arial", Times, serif;
  color: black;
  text-align: center;
}

body, td {
   font-size: 14px;
}
code.r{
  font-size: 13px;
}
pre {
  font-size: 13px
}
h1 { /* Header 1 */
  font-size: 16px;
  color: DarkBlue;
}
h2 { /* Header 2 */
    font-size: 16px;
  color: DarkBlue;
}
h3 { /* Header 3 */
  font-size: 15px;
  font-family: "Times New Roman", Times, serif;
  color: DarkBlue;

</style>

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r functions, include=FALSE}
# A function for captioning and referencing images
fig <- local({
    i <- 0
    ref <- list()
    list(
        cap=function(refName, text) {
            i <<- i + 1
            ref[[refName]] <<- i
            paste("Figure ", i, ": ", text, sep="")
        },
        ref=function(refName) {
            ref[[refName]]
        })
})
```




# Introduction

The development of `'opitools'` is to address the lack of tools for carrying out opinion impact analysis of a digital text document (DTD). The package functions can be categorized into two groups, namely (1) exploratory - for exploring terms in a document, e.g. importance of words and their statistical distribution, and (2) analytical - for computing metrics for the impact analysis. The potential of `opitools` for application to a wide variety of domains is demonstrated in this vignette with examples from the law enforcement, transport and politics.


### Setting the Working directory

```{r, message=FALSE, eval=FALSE}
WORKING_DIR <- 'C:/R/Github/JGIS_Policing_COVID-19'

#setting working directory
setwd(WORKING_DIR)
```


### Installing libraries
```{r, include=TRUE, message=FALSE, eval=TRUE}

library(opitools) #for impact analysis
require(knitr)
library(kableExtra)
library(dplyr)
library(cowplot)
#library(rtweet) #for data download
#library(twitteR) #for setting up Twitter authorization
#library(wordcloud2)
#library(tibble)
#library(tm)
#library(dplyr)

```

# Example datasets

In order to demonstrate the utility of `opitools` for application in a wide variety of domains, the following example datasets are used:

```{r, echo=FALSE, include=FALSE}
col1 <- c("1", "2", "3")
col2 <- c("`policing_dtd`","`reviews_dtd`","`debate_dtd`")
col3 <- c("`Law Enforcement`","`Transport`", "`Politics`")
col4 <- c("A digital text document (DTD) containing twitter posts on police/policing during the 2020 COVID-19 pandemic", "A DTD containing customer reviews of the Piccadilly train station (Manchester, uk). Data is downloaded from the www.tripadvisor.co.uk'. The records cover from July 2016 to March 2021."," A DTD containing individual comments on the video showing the debate between two US presidential nominees (Donald Trump and Hillary Clinton) in Sept. 2016. (Credit: NBC News).")
col5 <- c("www.twitter.com", "www.tripadvisor.co.uk","www.youtube.com")
tble1 <- data.frame(col1, col2, col3, col4, col5)
tble1 <- tble1
```



```{r table1, results='asis', echo=FALSE, tidy.opts=list(width.cutoff=50)}
knitr::kable(tble1, caption = "Table 1. `Example datasets`", col.names = c("SN","Data","Application","Details", "Data Source")) %>%
  kable_styling(full_width = F) %>%
  column_spec(1, bold = T, border_right = T) %>%
  column_spec(2, width = "8em", background = "white") %>%
  column_spec(3, width = "12em", background = "white") %>%
  column_spec(4, width = "16em", background = "white")#%>%
  #row_spec(3:5, bold = T, color = "white", background = "#D7261E")
```
 

# Functions

The function in `'opitools'` can be categorized into two groups, namely (1) exploratory - for exploring terms in a document, e.g. importance of words and their statistical distribution, and (2) analytical - for computing metrics for the impact analysis. 

### Exploratory function

Table 2 shows two exploratory functions embedded in `'opitools'`, namely `'word_distrib'` and `'word_importance'`. Details as follow:

```{r, echo=FALSE, include=FALSE}
col1 <- c("1", "2")
col2 <- c("`word_distrib`","`word_importance`")
col3 <- c("`Words Distribution`","`Importance of words (terms) embedded in a text document`")
col4 <- c("Examines the extent to which words in a DTD follow the Zipf's distribution (Zipf 1934). The Zipf's distribution  models the ideal natural language text", "Produces a table or graphic that highlights the importance of individual words(terms) in a DTD.")
tble2 <- data.frame(col1, col2, col3, col4)
tble2 <- tble2
```

```{r table2, results='asis', echo=FALSE, tidy.opts=list(width.cutoff=50)}
knitr::kable(tble2, caption = "Table 2. `Exploratory` functions", col.names = c("SN","Function","Title","Description")) %>%
  kable_styling(full_width = F) %>%
  column_spec(1, bold = T, border_right = T) %>%
  column_spec(2, width = "8em", background = "white") %>%
  column_spec(3, width = "12em", background = "white") %>%
  column_spec(4, width = "16em", background = "white")#%>%
  #row_spec(3:5, bold = T, color = "white", background = "#D7261E")
```


### Example data exploration

Below, the use of `'word_distrib'` and `'word_importance'` functions is demonstrated with the example datasets `'tweets'` (see documentations). The `'word_distrib'` can be used to answer the question: "To what extent is a given DTD close an ideal natural language text?". In other words, does the word usage in a DTD follow the ideal natural language modelled by the Zipf's distribution [@Zipf1936]? The `'word_distrib'` function models a DTD in terms of a Zipf's distribution by examining the log rank-frequency of the terms. In the model, we expect the frequency of each word to be inversely proportional to its rank in a frequency table. Using a randomised Twitter data (embedded in the package), 

```{r, message=FALSE, include = TRUE, eval=FALSE}

# Load data
data(tweets)

# Get the texts
tweets_dat <- as.data.frame(tweets[,1])

# Run function
plt = word_distrib(textdoc = tweets_dat)

#Show Zipf's distribution:

plt$plot

```

```{r figs1, echo=FALSE, fig.width=5,fig.height=6,fig.align="center", fig.cap=fig$cap("figs1", "Data freq. plot vs. Zipf's distribution")}
knitr::include_graphics("zipf.png")
```

For a natural language text, the Zipf's distribution plot has a negative slope with all points falling on a straight line. Any variance from this ideal trend line can be attributed to imperfections in the word usage. For example, the presence of a wide range of strange terms or made-up words can cause an imperfection of the text document. From Figure `r fig$ref("figs1")` the graph can be divided into the three sections: the upper, the middle and the lower sections. By fitting a regression line (an ideal Zipf's distribution), we can see what the slope of the upper section is quite different from the middle and the lower sections of the graph. The variance at the high rank indicates an imperfection because a corpus of English language would generally contain adequate number of common words, such as 'the', 'of', and 'at', and thus ensure alignment on a straight line. For Twitter data, this variance suggests a significant use of abbreviation of common words, such as using "&" or "nd" instead of the word "and". Apart from the small variance at the upper section of the graph, we can state that the law holds within most parts of the Twitter data.

The second exploratory function `'word_importance'` can be used to highlight the level of importance of each word in a DTD. The highlighted words can then be used to identify different themes (or subjects) that are inherent within or related to the DTD in question. Two metrics, namely (i) `'term frequency (tf)'` and `term frequency inverse document frequency (tf-idf)` [@Silge2016] are provided in the function. Below are sample results from the function using the datasets in `Table 1` with the `'tf'` metric. The function draws from `wordcloud2` package in R [@Dawei2018], in order to render the graphics as shown in Figure 2.

```{r, message=FALSE, include = TRUE, eval=FALSE}

#Load datasets

data("policing_dtd")
data("reviews_dtd")
data("debate_dtd")


p1 <- word_importance(textdoc = policing_dtd, metric= "tf", n_top=5,
                           words_to_filter=c("police","policing"))

#Note: 'words_to_filter' parameter is used to eliminate non-necessary words that 
#may be too dominant in the DTD.

p2 <- word_importance(textdoc = reviews_dtd, metric= "tf", n_top=5, 
                           words_to_filter=c("station", "manchester","train")) 

#output3 <- word_importance(textdoc = debate_otd, metric= "tf", n_top=5)

p1$plot
p2$plot

```

```{r figs2, echo=FALSE, fig.width=3,fig.height=4,fig.align="center", fig.cap=fig$cap("figs2", "Highlighting words importance from a DTD")}
knitr::include_graphics("wordcloud.png")
```

In Figure `r fig$ref("figs2")`, the size of a word represents its level of importance according to the 'terms frequency' metric (see documentation). From each graphic, a user can easily identify related words that denote certain themes or subjects within the document. In Figure 2A, words such as lockdown, infect and covid, refers to the pandemic-related sentiment under which the policing were operating as at the time that the datasets were generated. Does the pandemic situation has any impacts on the public opinion of the police activities? Figure 2B highlights related words, such as restaurant, shops, food and coffee, which refer to refreshments that can be found at the train station. Do these items impacts the overall customers' opinion of the train services?. Similarly, do the signages at the station, such as board, map and display influences customers reviews of the station?. These questions can be answered using the analytical functions of the package.


### Analytical functions

Table 3 shows the list of impact analytical functions in the `'opitools'` package.

```{r, echo=FALSE, include=FALSE}
col1 <- c("3", "4", "5")
col2 <- c("`opi_score`","`opi_sim`", "`opi_impact`")
col3 <- c("`Opinion score of a text document`",
          "`Simulates the opinion expectation distribution of a text document`",
          "`Statistical assessment of impacts of a specified theme (or subject) from a document`")
col4 <- c("Given a text document, this function computes the overall opinion score based on the proportion of text records classified as expressing positive, negative or a neutral sentiment about the subject.",  "This function simulates the expectation distribution of the observed opinion score (computed using the `opi_score` function).",  "This function assesses the impacts of a theme (or subject) on the overall opinion computed for a text document. The text records relating to the theme in question should be identified and provided as input to this function")
tble3 <- data.frame(col1, col2, col3, col4)
tble3<- tble3
```

```{r table3, results='asis', echo=FALSE, tidy.opts=list(width.cutoff=50)}
knitr::kable(tble3, caption = "Table 3. `Impact Analytical` function", col.names = c("SN","Function","Title","Description")) %>%
  kable_styling(full_width = F) %>%
  column_spec(1, bold = T, border_right = T) %>%
  column_spec(2, width = "8em", background = "white") %>%
  column_spec(3, width = "12em", background = "white") %>%
  column_spec(4, width = "16em", background = "white")#%>%
  #row_spec(3:5, bold = T, color = "white", background = "#D7261E")
```

The key analytical function is the `opi_impact()` which draws from `opi_score()` and `opi_sim()` to compute the observed opinion score and its expectations, respectively. The observed opinion score is compared with the expectation in order to derive the statistical significance of the impacts. The aforementioned questions can be answered by running the following codes: 



The impact analysis can be performed as follows: 

```{r, message=FALSE, include = TRUE, eval=FALSE}

#Application: Law enforcement

# Load DTD
data(policing_dtd)

# Load theme keywords
data(covid_keys)

# Run the analysis
output1 <- opi_impact(policing_dtd, sec_keywords=covid_keys, metric = 1,
                       fun = NULL, nsim = 99, alternative="two.sided",
                       quiet=TRUE)
print(output1)

```

To print results: 

```{r, echo=TRUE, message=FALSE, eval=FALSE}

> output1

#$test
#[1] "Test of significance (Randomization testing)"

#$criterion
#[1] "two.sided"

#$exp_summary
#   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
# -8.240  -5.880  -5.880  -4.837  -3.530  -1.180 

#$p_table

#|observed_score |S_beat |nsim |pvalue |signif |
#|:--------------|:------|:----|:------|:------|
#|-5.88          |51     |99   |0.52   |'      |

#$p_key
#[1] "0.99'"   "0.05*"   "0.025**" "0.01***"

#$p_formula
#[1] "(S_beat + 1)/(nsim + 1)"

#$plot
```

* The descriptions of output variables are as follow:

  + `test` - title of the analysis

  + `criterion` - criterion for determining the significance value

  + `exp_summary` - summary of expected opinion scores
  
  + `p_table` - details of Statistical Significance

  + `p_key` - keys for interpreting the statistical significance value

  + `p_formula` - function of opinion score employed
  
  + `plot` - plot showing Percentage proportion of classes


The output shows that COVID-19 pandemic has not had significant impacts on the public opinion concerning neighbourhood policing. This is indicated by a non-significant pvalue `0.52`. 

To display the graphics showing the proportion of various sentiment classes (as in Figure `r fig$ref("figs3")`), type `output$plot` in the console.

```{r figs3, echo=FALSE, fig.width=5,fig.height=6,fig.align="center", fig.cap=fig$cap("figs3", "Percentage proportion of classes")}
knitr::include_graphics("likert.png")
```

Using the customers' reviews data and examining whether the refreshment items in and around the train station have significant impacts on the overall customers' opinion of the train services? 


```{r, message=FALSE, include = TRUE, eval=FALSE}

#Application: Transport

# Load DTD
data(reviews_dtd)

# Load theme keywords
data(refreshment_keys)

# Run the analysis
output2 <- opi_impact(reviews_dtd, sec_keywords=refreshment_keys, metric = 1,
                       fun = NULL, nsim = 99, alternative="two.sided",
                       quiet=TRUE)
print(output2)

```


Printing the results:

```{r, echo=TRUE, message=FALSE, eval=FALSE}

> output2

#$test
#[1] "Test of significance (Randomization testing)"

#$criterion
#[1] "two.sided"

#$exp_summary
#   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
#  53.38   58.90   60.40   60.37   62.41   67.42 

#$p_table

#|observed_score |S_beat |nsim |pvalue |signif |
#|:--------------|:------|:----|:------|:------|
#|67.92          |0      |99   |0.01   |***    |

#$p_key
#[1] "0.99'"   "0.05*"   "0.025**" "0.01***"

#$p_formula
#[1] "(S_beat + 1)/(nsim + 1)"

$plot

```

From the above, the pvalue = 0.01 indicate significant impacts of refreshment items and outlets on the overall opinion of the train station. The observed score of `67.92` indicate a generally positive reviews by the customers. Similarly, using the same data, we can examine the impacts of signages around the station on the overall customer reviews, as follow:

```{r, message=FALSE, include = TRUE, eval=FALSE}

#Application: Transport

# Load DTD
data(reviews_dtd)

# Load theme keywords
data(signage_keys)

# Run the analysis
output3 <- opi_impact(reviews_dtd, sec_keywords=signage_keys, metric = 1,
                       fun = NULL, nsim = 99, alternative="two.sided",
                       quiet=TRUE)
print(output3)

```

Results:

```{r, echo=TRUE, message=FALSE, eval=FALSE}

> output3

#$test
#[1] "Test of significance (Randomization testing)"

#$criterion
#[1] "two.sided"

#$exp_summary
#   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
#  58.90   64.41   65.91   65.66   66.92   69.92 

#$p_table

#|observed_score |S_beat |nsim |pvalue |signif |
#|:--------------|:------|:----|:------|:------|
#|67.92          |9      |99   |0.1    |'      |

#$p_key
#[1] "0.99'"   "0.05*"   "0.025**" "0.01***"

#$p_formula
#[1] "(S_beat + 1)/(nsim + 1)"

#$plot

```

The results indicate a non-significant impacts.

Lastly, using the `'debate_dtd'` datasets, we can examine how each candidate has impacted the overall opinion on the debate. First, using the democratic candicate, Hillary Clinton: 

```{r, message=FALSE, include = TRUE, eval=FALSE}

#Application: Politics

# Load DTD
data(debate_dtd)

# The theme keyword can also be specified as a vector of characters, such as: 
keys <- c("Clinton", "Hillary")

# Run the analysis
output4 <- opi_impact(reviews_dtd, sec_keywords=signage_keys, metric = 1,
                       fun = NULL, nsim = 99, alternative="two.sided",
                       quiet=TRUE)
print(output4)

```

Results:


The results show a .....

```{r, message=FALSE, include = TRUE, eval=FALSE}

#Application: Politics

# Load DTD
data(debate_dtd)

# The theme keyword can also be specified as a vector of characters, such as: 
keys <- c("Donald", "Trump")

# Run the analysis
output5 <- opi_impact(debate_dtd, sec_keywords=keys, metric = 1,
                       fun = NULL, nsim = 99, alternative="two.sided",
                       quiet=TRUE)
print(output5)

```

Results:


The results show a .....


### Using a user-defined opinion score function

As the definition of opinion score function may vary from one application domain to another, a user can specify a pre-defined opinion score function. For instance, [@Razorfish2019] defines opinion score of a product brand as `score = (P + O - N)/(P + O + N)`, where `P`, `O`, and `N`, represent the amount/proportion of positive, neutral and negative, sentiments, respectively. Using a user-define function, the analysis can be re-run as follows: 

First define the function: 

```{r, echo=TRUE, message=FALSE, eval=FALSE}

#define opinion score function
myfun <- function(P, N, O){
   score <- (P + O - N)/(P + O + N)
   return(score)
}

```

The last example analysis can be re-run using the above user-defined opinion score as follows:

```{r, echo=TRUE, message=FALSE, eval=FALSE}

output6 <- opi_impact(debate_dtd, sec_keywords=keys, metric = 5,
                       fun = myfun, nsim = 99, alternative="two.sided",
                       quiet=TRUE)
```

Print results: 

```{r, echo=TRUE, message=FALSE, eval=FALSE}

> output6

#> $test
#> [1] "Test of significance (Randomization testing)"
#> 


```

Results:


The results show a .....


Based on the user defined opinion score function, the new opinion score is estimated as -0.234, while the `pvalue` now equals to 1 (non-significant). This implies that the outcome of whether a secondary subject has had a significant impact on the primary subject is also dependent on the opinion score function specified.


# Conclusion

The `opitools` package has been developed in order to aid the replication of the study [@Adepeju2021] for other application fields. In essence, the utility of the functions contained in this package is not limited to law enforcement(s) and public health, but rather can be applicable to several other public services more generally. This package is being updated on a regular basis to add more functionalities. 

We encourage users to report any bugs encountered while using the package so that they can be fixed immediately. Welcome contributions to this package which will be acknowledged accordingly. 

# References
